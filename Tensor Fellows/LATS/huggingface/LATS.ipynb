{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "826012c4-1395-4517-85d1-1b4ececa1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index\n",
    "# !pip install llama-index-llms-huggingface\n",
    "# !pip install llama-index-embeddings-huggingface\n",
    "# !pip install llama-index-embeddings-huggingface-api\n",
    "# !pip install --upgrade pip\n",
    "# !pip install llama-index-agent-lats\n",
    "# !pip install clingo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e281fe-c259-406c-9125-786510b7a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = \"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\"\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b00452d8-12dc-40d1-8d95-6422e069dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=hf_token,\n",
    ")\n",
    "\n",
    "stopping_ids = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8118cd0-0240-4f27-bc2d-9d04c37162c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kraines5/.local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/kraines5/.local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/kraines5/.local/lib/python3.11/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d122e3d9a5194cdd8ffce4c3a764fd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    model_kwargs={\n",
    "        \"token\": hf_token,\n",
    "        \"torch_dtype\": torch.bfloat16,\n",
    "    },\n",
    "    generate_kwargs={\n",
    "        \"do_sample\": True,\n",
    "        \"temperature\": 0.6,\n",
    "        \"top_p\": 0.9,\n",
    "    },\n",
    "    tokenizer_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    tokenizer_kwargs={\"token\": hf_token},\n",
    "    stopping_ids=stopping_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ba55b3-6b5b-4271-97fc-8a0b134e6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-11 23:10:21--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/uber_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1880483 (1.8M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/uber_2021.pdf’\n",
      "\n",
      "data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-11-11 23:10:21 (40.9 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
      "\n",
      "--2024-11-11 23:10:21--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10k/lyft_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1440303 (1.4M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/lyft_2021.pdf’\n",
      "\n",
      "data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.006s  \n",
      "\n",
      "2024-11-11 23:10:22 (237 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/core/embeddings/utils.py:59\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[0;34m(embed_model, callback_manager)\u001b[0m\n\u001b[1;32m     58\u001b[0m     embed_model \u001b[38;5;241m=\u001b[39m OpenAIEmbedding()\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mvalidate_openai_api_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43membed_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/embeddings/openai/utils.py:103\u001b[0m, in \u001b[0;36mvalidate_openai_api_key\u001b[0;34m(api_key)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m openai_api_key:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(MISSING_API_KEY_ERROR_MESSAGE)\n",
      "\u001b[0;31mValueError\u001b[0m: No API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m uber_docs \u001b[38;5;241m=\u001b[39m SimpleDirectoryReader(\n\u001b[1;32m     20\u001b[0m     input_files\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/10k/uber_2021.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     21\u001b[0m )\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# build index\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m lyft_index \u001b[38;5;241m=\u001b[39m \u001b[43mVectorStoreIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlyft_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m uber_index \u001b[38;5;241m=\u001b[39m VectorStoreIndex\u001b[38;5;241m.\u001b[39mfrom_documents(uber_docs)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# persist index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/core/indices/base.py:119\u001b[0m, in \u001b[0;36mBaseIndex.from_documents\u001b[0;34m(cls, documents, storage_context, show_progress, callback_manager, transformations, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     docstore\u001b[38;5;241m.\u001b[39mset_document_hash(doc\u001b[38;5;241m.\u001b[39mget_doc_id(), doc\u001b[38;5;241m.\u001b[39mhash)\n\u001b[1;32m    112\u001b[0m nodes \u001b[38;5;241m=\u001b[39m run_transformations(\n\u001b[1;32m    113\u001b[0m     documents,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     transformations,\n\u001b[1;32m    115\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/core/indices/vector_store/base.py:72\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[0;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_async \u001b[38;5;241m=\u001b[39m use_async\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_nodes_override \u001b[38;5;241m=\u001b[39m store_nodes_override\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     70\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mSettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_model\u001b[49m\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     77\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[1;32m     78\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     85\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/core/settings.py:64\u001b[0m, in \u001b[0;36m_Settings.embed_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the embedding model.\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_embed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mcallback_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/llama_index/core/embeddings/utils.py:66\u001b[0m, in \u001b[0;36mresolve_embed_model\u001b[0;34m(embed_model, callback_manager)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`llama-index-embeddings-openai` package not found, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease run `pip install llama-index-embeddings-openai`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 66\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not load OpenAI embedding model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you intended to use OpenAI, please check your OPENAI_API_KEY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mConsider using embed_model=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisit our documentation for more embedding options: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.llamaindex.ai/en/stable/module_guides/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings.html#modules\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m******\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# for image multi-modal embeddings\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m embed_model\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: \n******\nCould not load OpenAI embedding model. If you intended to use OpenAI, please check your OPENAI_API_KEY.\nOriginal error:\nNo API key found for OpenAI.\nPlease set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\nAPI keys can be found or created at https://platform.openai.com/account/api-keys\n\nConsider using embed_model='local'.\nVisit our documentation for more embedding options: https://docs.llamaindex.ai/en/stable/module_guides/models/embeddings.html#modules\n******"
     ]
    }
   ],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "def blocks_world_engine(query):\n",
    "    prompt_template = f\"\"\"\n",
    "    I am working on a Blocks World problem, and here is a proposed next step to solve the prolem:\n",
    "\n",
    "    Proposed Solution:\n",
    "    {query}\n",
    "\n",
    "    Is this solution valid? Does it work towards the goal?\n",
    "\n",
    "    Please respond with \"valid\" if the solution works towards the goal or \"not valid\" if it doesn't.\n",
    "    \"\"\"\n",
    "\n",
    "    responses = []\n",
    "\n",
    "    # Ask the LLM 5 times\n",
    "    for _ in range(5):\n",
    "        response = llm.complete(prompt_template).strip().lower()\n",
    "        responses.append(response)\n",
    "\n",
    "    # Count the occurrences of \"valid\" and \"not valid\"\n",
    "    counts = Counter(responses)\n",
    "\n",
    "    # Determine majority response\n",
    "    if counts[\"valid\"] >= 3:\n",
    "        return \"The solution is good!\"\n",
    "    else:\n",
    "        return \"The solution is not good.\"\n",
    "\n",
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=blocks_world_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"blocks_world_tool\",\n",
    "            description=(\n",
    "                '''\n",
    "                Provide a proposed solution for the next step to the group of LLMs.\n",
    "                It will provide a majority ruling as to whether or not it is a valid\n",
    "                solution.\n",
    "                '''\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3bfbe-2b88-4d74-8e58-84f993937803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent.lats import LATSAgentWorker\n",
    "\n",
    "agent_worker = LATSAgentWorker(\n",
    "    query_engine_tools,\n",
    "    llm=llm,\n",
    "    num_expansions=2,\n",
    "    max_rollouts=3,\n",
    "    verbose=True,\n",
    ")\n",
    "agent = agent_worker.as_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b57543-4991-4706-85f7-893594c30ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = agent.create_task(\n",
    "    '''I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\n",
    "    \n",
    "    Pick up a block\n",
    "    Unstack a block from on top of another block\n",
    "    Put down a block\n",
    "    Stack a block on top of another block\n",
    "    \n",
    "    I have the following restrictions on my actions:\n",
    "    I can only pick up or unstack one block at a time.\n",
    "    I can only pick up or unstack a block if my hand is empty.\n",
    "    I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\n",
    "    I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\n",
    "    I can only unstack a block from on top of another block if the block I am unstacking is clear.\n",
    "    Once I pick up or unstack a block, I am holding the block.\n",
    "    I can only put down a block that I am holding.\n",
    "    I can only stack a block on top of another block if I am holding the block being stacked.\n",
    "    I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\n",
    "    Once I put down or stack a block, my hand becomes empty.\n",
    "    Once you stack a block on top of a second block, the second block is no longer clear.\n",
    "    \n",
    "    [STATEMENT]\n",
    "    As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.\n",
    "    My goal is to have that the orange block is on top of the red block.\n",
    "    \n",
    "    My plan is as follows:\n",
    "    \n",
    "    [PLAN]'''\n",
    ")\n",
    "\n",
    "step_output = agent.run_step(task.task_id)\n",
    "for step in (\n",
    "    step_output.task_step.step_state[\"root_node\"].children[0].current_reasoning\n",
    "):\n",
    "    print(step)\n",
    "    print(\"---------\")\n",
    "\n",
    "for step in (\n",
    "    step_output.task_step.step_state[\"root_node\"]\n",
    "    .children[0]\n",
    "    .children[0]\n",
    "    .current_reasoning\n",
    "):\n",
    "    print(step)\n",
    "    print(\"---------\")\n",
    "\n",
    "# repeat until the last step is reached\n",
    "# while not step_output.is_last:\n",
    "#     step_output = agent.run_step(task.task_id)\n",
    "\n",
    "# response = agent.finalize_response(task.task_id)\n",
    "\n",
    "agent.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c5f34-9c2d-4f66-95a2-0f084e6e6a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = agent.chat(\n",
    "#     '''I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do\n",
    "    \n",
    "#     Pick up a block\n",
    "#     Unstack a block from on top of another block\n",
    "#     Put down a block\n",
    "#     Stack a block on top of another block\n",
    "    \n",
    "#     I have the following restrictions on my actions:\n",
    "#     I can only pick up or unstack one block at a time.\n",
    "#     I can only pick up or unstack a block if my hand is empty.\n",
    "#     I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up.\n",
    "#     I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block.\n",
    "#     I can only unstack a block from on top of another block if the block I am unstacking is clear.\n",
    "#     Once I pick up or unstack a block, I am holding the block.\n",
    "#     I can only put down a block that I am holding.\n",
    "#     I can only stack a block on top of another block if I am holding the block being stacked.\n",
    "#     I can only stack a block on top of another block if the block onto which I am stacking the block is clear.\n",
    "#     Once I put down or stack a block, my hand becomes empty.\n",
    "#     Once you stack a block on top of a second block, the second block is no longer clear.\n",
    "    \n",
    "#     [STATEMENT]\n",
    "#     As initial conditions I have that, the red block is clear, the yellow block is clear, the hand is empty, the red block is on top of the blue block, the yellow block is on top of the orange block, the blue block is on the table and the orange block is on the table.\n",
    "#     My goal is to have that the orange block is on top of the red block.\n",
    "    \n",
    "#     My plan is as follows:\n",
    "    \n",
    "#     [PLAN]'''\n",
    "# )\n",
    "\n",
    "# print(str(response))\n",
    "\n",
    "# agent.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8ad73-108f-49a5-b07d-354690c8c1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.15.0",
   "language": "python",
   "name": "tensorflow-gpu-2.15.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
